# ğŸš€ êµ¬ê¸€ ì½”ë©ì—ì„œ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ê°€ì´ë“œ

## ğŸ“‹ ê°œìš”
ì´ ê°€ì´ë“œëŠ” êµ¬ê¸€ ì½”ë©ì—ì„œ ìŠ¤ë§ˆíŠ¸ ë¹Œë”© ì—ë„ˆì§€ ê´€ë¦¬ ì‹œìŠ¤í…œì˜ ì „ì²´ íŒŒì´í”„ë¼ì¸(ì „ì²˜ë¦¬ë¶€í„° ëª¨ë¸ ê°œë°œê¹Œì§€)ì„ ì‹¤í–‰í•˜ëŠ” ë°©ë²•ì„ ì„¤ëª…í•©ë‹ˆë‹¤.

## ğŸ¯ ì‹¤í–‰ ìˆœì„œ
1. í™˜ê²½ ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜
2. ì›ë³¸ ë°ì´í„° ì—…ë¡œë“œ
3. ë°ì´í„° ì „ì²˜ë¦¬
4. ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ ê°œë°œ
5. ê²°ê³¼ ë¶„ì„ ë° ì‹œê°í™”

---

## 1ë‹¨ê³„: í™˜ê²½ ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜

```python
# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜
!pip install xgboost lightgbm joblib plotly scikit-learn scipy

# ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# ë¨¸ì‹ ëŸ¬ë‹ ë¼ì´ë¸ŒëŸ¬ë¦¬
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, IsolationForest
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder
import xgboost as xgb
import lightgbm as lgb
import joblib
import json
import os

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = 'DejaVu Sans'
plt.rcParams['axes.unicode_minus'] = False

print("âœ… í™˜ê²½ ì„¤ì • ì™„ë£Œ!")
```

---

## 2ë‹¨ê³„: ì›ë³¸ ë°ì´í„° ì—…ë¡œë“œ

```python
from google.colab import files

# data í´ë” ìƒì„±
os.makedirs('data/processed', exist_ok=True)

print("ğŸ“ data í´ë”ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
print("\nğŸ“¤ ì›ë³¸ ë°ì´í„° íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”:")
print("   - synthetic_building_data.csv (í•©ì„± ê±´ë¬¼ ë°ì´í„°)")

# íŒŒì¼ ì—…ë¡œë“œ
uploaded = files.upload()

# ì—…ë¡œë“œëœ íŒŒì¼ë“¤ì„ data/processed í´ë”ë¡œ ì´ë™
for filename in uploaded.keys():
    if filename.endswith('.csv'):
        os.rename(filename, f'data/processed/{filename}')
        print(f"âœ… {filename} ì—…ë¡œë“œ ì™„ë£Œ")

print("\nğŸ‰ ë°ì´í„° ì—…ë¡œë“œ ì™„ë£Œ!")
```

---

## 3ë‹¨ê³„: ë°ì´í„° ì „ì²˜ë¦¬ í´ë˜ìŠ¤ ì •ì˜

```python
class SmartBuildingPreprocessor:
    """ìŠ¤ë§ˆíŠ¸ ë¹Œë”© ì—ë„ˆì§€ ë°ì´í„° ì „ì²˜ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, data_path='data/processed/synthetic_building_data.csv'):
        self.data_path = data_path
        self.scalers = {}
        self.label_encoders = {}
        self.feature_columns = []
        self.target_column = 'power_consumption'
        
    def load_data(self):
        """ë°ì´í„° ë¡œë“œ ë° ê¸°ë³¸ ì •ë³´ í™•ì¸"""
        print("ğŸ“Š ë°ì´í„° ë¡œë“œ ì¤‘...")
        self.df = pd.read_csv(self.data_path)
        print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {self.df.shape}")
        
        # íƒ€ì„ìŠ¤íƒ¬í”„ ë³€í™˜
        self.df['timestamp'] = pd.to_datetime(self.df['timestamp'])
        self.df = self.df.sort_values('timestamp').reset_index(drop=True)
        
        return self.df
    
    def create_time_features(self):
        """ì‹œê³„ì—´ íŠ¹ì„± ìƒì„±"""
        print("â° ì‹œê³„ì—´ íŠ¹ì„± ìƒì„± ì¤‘...")
        
        # ê¸°ë³¸ ì‹œê°„ íŠ¹ì„±
        self.df['hour'] = self.df['timestamp'].dt.hour
        self.df['day_of_week'] = self.df['timestamp'].dt.dayofweek
        self.df['month'] = self.df['timestamp'].dt.month
        self.df['day_of_year'] = self.df['timestamp'].dt.dayofyear
        self.df['week_of_year'] = self.df['timestamp'].dt.isocalendar().week
        
        # ê³„ì ˆ íŠ¹ì„±
        self.df['season'] = pd.cut(self.df['month'], 
                                  bins=[0, 3, 6, 9, 12], 
                                  labels=['ê²¨ìš¸', 'ë´„', 'ì—¬ë¦„', 'ê°€ì„'])
        
        # ì—…ë¬´ ê´€ë ¨ íŠ¹ì„±
        self.df['is_weekend'] = (self.df['day_of_week'] >= 5).astype(int)
        self.df['is_business_hour'] = ((self.df['hour'] >= 8) & (self.df['hour'] <= 18)).astype(int)
        self.df['is_peak_hour'] = ((self.df['hour'] >= 9) & (self.df['hour'] <= 17)).astype(int)
        self.df['is_night'] = ((self.df['hour'] >= 22) | (self.df['hour'] <= 6)).astype(int)
        
        # ì‹œê°„ëŒ€ë³„ ì¹´í…Œê³ ë¦¬
        self.df['time_period'] = pd.cut(self.df['hour'], 
                                       bins=[0, 6, 12, 18, 24], 
                                       labels=['ìƒˆë²½', 'ì˜¤ì „', 'ì˜¤í›„', 'ì €ë…'])
        
        print("âœ… ì‹œê³„ì—´ íŠ¹ì„± ìƒì„± ì™„ë£Œ")
        return self.df
    
    def create_temperature_features(self):
        """ì˜¨ë„ ê´€ë ¨ íŠ¹ì„± ìƒì„±"""
        print("ğŸŒ¡ï¸ ì˜¨ë„ ê´€ë ¨ íŠ¹ì„± ìƒì„± ì¤‘...")
        
        # ì˜¨ë„ ë¹„ì„ í˜• íŠ¹ì„±
        self.df['temperature_squared'] = self.df['temperature'] ** 2
        self.df['temperature_cubed'] = self.df['temperature'] ** 3
        
        # ì˜¨ìŠµë„ ìƒí˜¸ì‘ìš©
        self.df['temp_humidity_interaction'] = self.df['temperature'] * self.df['humidity']
        
        # ì²´ê°ì˜¨ë„
        self.df['feels_like_temp'] = (0.5 * self.df['temperature'] + 
                                     0.3 * self.df['humidity'] + 
                                     0.2 * (self.df['temperature'] * self.df['humidity'] / 100))
        
        # ë‚œë°©/ëƒ‰ë°©ë„ì¼
        base_temp = 18
        self.df['heating_degree_days'] = np.maximum(base_temp - self.df['temperature'], 0)
        self.df['cooling_degree_days'] = np.maximum(self.df['temperature'] - base_temp, 0)
        
        # ì¾Œì êµ¬ê°„
        self.df['comfort_zone'] = ((self.df['temperature'] >= 18) & 
                                  (self.df['temperature'] <= 26)).astype(int)
        
        # ì˜¨ë„ êµ¬ê°„ë³„ ì¹´í…Œê³ ë¦¬
        self.df['temp_category'] = pd.cut(self.df['temperature'], 
                                         bins=[-10, 0, 10, 20, 30, 50], 
                                         labels=['ë§¤ìš°ì¶”ì›€', 'ì¶”ì›€', 'ì‹œì›í•¨', 'ë”°ëœ»í•¨', 'ë”ì›€'])
        
        print("âœ… ì˜¨ë„ ê´€ë ¨ íŠ¹ì„± ìƒì„± ì™„ë£Œ")
        return self.df
    
    def create_occupancy_features(self):
        """ê³µì‹¤ë¥  ê´€ë ¨ íŠ¹ì„± ìƒì„±"""
        print("ğŸ‘¥ ê³µì‹¤ë¥  ê´€ë ¨ íŠ¹ì„± ìƒì„± ì¤‘...")
        
        # ê³µì‹¤ ì´ì§„ ë¶„ë¥˜
        self.df['occupancy_binary'] = (self.df['occupancy'] > 0).astype(int)
        
        # ê³µì‹¤ ìˆ˜ì¤€ ë¶„ë¥˜
        self.df['occupancy_level'] = pd.cut(self.df['occupancy'], 
                                           bins=[0, 20, 60, 100], 
                                           labels=['ë‚®ìŒ', 'ë³´í†µ', 'ë†’ìŒ'])
        
        # ì‹œì°¨ íŠ¹ì„±
        for lag in [1, 2, 3, 6, 12, 24]:
            self.df[f'occupancy_lag_{lag}h'] = self.df['occupancy'].shift(lag)
        
        # ì´ë™í‰ê· 
        for window in [3, 6, 12, 24]:
            self.df[f'occupancy_rolling_mean_{window}h'] = self.df['occupancy'].rolling(window=window).mean()
            self.df[f'occupancy_rolling_std_{window}h'] = self.df['occupancy'].rolling(window=window).std()
        
        # ê³µì‹¤ ë³€í™”ìœ¨
        self.df['occupancy_change_rate'] = self.df['occupancy'].pct_change()
        
        # ê³µì‹¤ íŒ¨í„´ íŠ¹ì„±
        self.df['occupancy_trend'] = self.df['occupancy'].rolling(window=6).apply(
            lambda x: np.polyfit(range(len(x)), x, 1)[0] if len(x) > 1 else 0
        )
        
        print("âœ… ê³µì‹¤ë¥  ê´€ë ¨ íŠ¹ì„± ìƒì„± ì™„ë£Œ")
        return self.df
    
    def create_building_features(self):
        """ê±´ë¬¼ ê´€ë ¨ íŠ¹ì„± ìƒì„±"""
        print("ğŸ¢ ê±´ë¬¼ ê´€ë ¨ íŠ¹ì„± ìƒì„± ì¤‘...")
        
        # ê±´ë¬¼ë³„ ê°€ìƒ ë©´ì 
        self.df['building_floor_area'] = self.df['floor'] * 500
        
        # ê±´ë¬¼ë³„ ì—ë„ˆì§€ íš¨ìœ¨ì„± ì ìˆ˜
        building_efficiency = {
            'B001': 0.8, 'B002': 0.9, 'B003': 0.7, 'B004': 0.85, 'B005': 0.75
        }
        self.df['building_efficiency_score'] = self.df['building_id'].map(building_efficiency)
        
        # ì¸µìˆ˜ë³„ íŠ¹ì„±
        self.df['floor_height_factor'] = self.df['floor'] * 3
        self.df['is_ground_floor'] = (self.df['floor'] == 1).astype(int)
        self.df['is_top_floor'] = (self.df['floor'] == 5).astype(int)
        
        # ê±´ë¬¼ë³„ í‰ê·  ì „ë ¥ ì‚¬ìš©ëŸ‰
        building_avg_power = self.df.groupby('building_id')['power_consumption'].mean()
        self.df['building_avg_power'] = self.df['building_id'].map(building_avg_power)
        
        # ê±´ë¬¼ë³„ ì „ë ¥ ì‚¬ìš© íŒ¨í„´
        building_power_std = self.df.groupby('building_id')['power_consumption'].std()
        self.df['building_power_std'] = self.df['building_id'].map(building_power_std)
        
        print("âœ… ê±´ë¬¼ ê´€ë ¨ íŠ¹ì„± ìƒì„± ì™„ë£Œ")
        return self.df
    
    def create_power_features(self):
        """ì „ë ¥ ì‚¬ìš©ëŸ‰ ê´€ë ¨ íŠ¹ì„± ìƒì„±"""
        print("âš¡ ì „ë ¥ ì‚¬ìš©ëŸ‰ ê´€ë ¨ íŠ¹ì„± ìƒì„± ì¤‘...")
        
        # ì „ë ¥ ì‚¬ìš©ëŸ‰ ë³€í™”ìœ¨
        self.df['power_change_rate'] = self.df['power_consumption'].pct_change()
        
        # ì „ë ¥ ì‚¬ìš©ëŸ‰ ì´ë™í‰ê· 
        for window in [3, 6, 12, 24]:
            self.df[f'power_rolling_mean_{window}h'] = self.df['power_consumption'].rolling(window=window).mean()
            self.df[f'power_rolling_std_{window}h'] = self.df['power_consumption'].rolling(window=window).std()
        
        # ì „ë ¥ ì‚¬ìš©ëŸ‰ íŠ¸ë Œë“œ
        self.df['power_trend'] = self.df['power_consumption'].rolling(window=6).apply(
            lambda x: np.polyfit(range(len(x)), x, 1)[0] if len(x) > 1 else 0
        )
        
        # ì „ë ¥ ì‚¬ìš©ëŸ‰ ë¶„ìœ„ìˆ˜
        self.df['power_quantile'] = pd.qcut(self.df['power_consumption'], 
                                           q=5, labels=['ë§¤ìš°ë‚®ìŒ', 'ë‚®ìŒ', 'ë³´í†µ', 'ë†’ìŒ', 'ë§¤ìš°ë†’ìŒ'])
        
        # ì „ë ¥ ì‚¬ìš©ëŸ‰ êµ¬ê°„
        self.df['power_category'] = pd.cut(self.df['power_consumption'], 
                                          bins=[0, 10, 30, 60, 100, 200], 
                                          labels=['ë¯¸ì‚¬ìš©', 'ì €ì „ë ¥', 'ë³´í†µ', 'ê³ ì „ë ¥', 'ìµœê³ ì „ë ¥'])
        
        print("âœ… ì „ë ¥ ì‚¬ìš©ëŸ‰ ê´€ë ¨ íŠ¹ì„± ìƒì„± ì™„ë£Œ")
        return self.df
    
    def create_interaction_features(self):
        """ìƒí˜¸ì‘ìš© íŠ¹ì„± ìƒì„±"""
        print("ğŸ”— ìƒí˜¸ì‘ìš© íŠ¹ì„± ìƒì„± ì¤‘...")
        
        # ì˜¨ë„ì™€ ê³µì‹¤ë¥  ìƒí˜¸ì‘ìš©
        self.df['temp_occupancy_interaction'] = self.df['temperature'] * self.df['occupancy']
        
        # ì‹œê°„ëŒ€ì™€ ê³µì‹¤ë¥  ìƒí˜¸ì‘ìš©
        self.df['hour_occupancy_interaction'] = self.df['hour'] * self.df['occupancy']
        
        # ê±´ë¬¼ íš¨ìœ¨ì„±ê³¼ ì „ë ¥ ì‚¬ìš©ëŸ‰ ìƒí˜¸ì‘ìš©
        self.df['efficiency_power_interaction'] = self.df['building_efficiency_score'] * self.df['power_consumption']
        
        # ì—…ë¬´ì‹œê°„ê³¼ ê³µì‹¤ë¥  ìƒí˜¸ì‘ìš©
        self.df['business_occupancy_interaction'] = self.df['is_business_hour'] * self.df['occupancy']
        
        # ê³„ì ˆê³¼ ì˜¨ë„ ìƒí˜¸ì‘ìš©
        season_encoded = self.df['season'].astype('category').cat.codes
        self.df['season_temp_interaction'] = season_encoded * self.df['temperature']
        
        print("âœ… ìƒí˜¸ì‘ìš© íŠ¹ì„± ìƒì„± ì™„ë£Œ")
        return self.df
    
    def handle_missing_values(self):
        """ê²°ì¸¡ê°’ ì²˜ë¦¬"""
        print("ğŸ§¹ ê²°ì¸¡ê°’ ì²˜ë¦¬ ì¤‘...")
        
        initial_missing = self.df.isnull().sum().sum()
        if initial_missing == 0:
            print("âœ… ê²°ì¸¡ê°’ì´ ì—†ìŠµë‹ˆë‹¤.")
            return self.df
        
        # ì‹œê³„ì—´ ë°ì´í„°ì˜ ê²½ìš° ì „ì§„ ì±„ìš°ê¸° ì‚¬ìš©
        self.df = self.df.fillna(method='ffill')
        self.df = self.df.fillna(method='bfill')
        
        # ìˆ«ìí˜• ì»¬ëŸ¼ì˜ ê²½ìš° í‰ê· ê°’ìœ¼ë¡œ ì±„ìš°ê¸°
        numeric_columns = self.df.select_dtypes(include=[np.number]).columns
        self.df[numeric_columns] = self.df[numeric_columns].fillna(self.df[numeric_columns].mean())
        
        final_missing = self.df.isnull().sum().sum()
        print(f"âœ… ê²°ì¸¡ê°’ ì²˜ë¦¬ ì™„ë£Œ: {initial_missing} -> {final_missing}")
        
        return self.df
    
    def detect_and_handle_outliers(self, method='isolation_forest'):
        """ì´ìƒì¹˜ íƒì§€ ë° ì²˜ë¦¬"""
        print("ğŸ” ì´ìƒì¹˜ íƒì§€ ë° ì²˜ë¦¬ ì¤‘...")
        
        # ì „ë ¥ ì‚¬ìš©ëŸ‰ ì´ìƒì¹˜ íƒì§€
        power_consumption = self.df['power_consumption'].values.reshape(-1, 1)
        
        if method == 'isolation_forest':
            iso_forest = IsolationForest(contamination=0.1, random_state=42)
            outliers = iso_forest.fit_predict(power_consumption)
            outlier_indices = np.where(outliers == -1)[0]
        
        # ì´ìƒì¹˜ë¥¼ ì¤‘ì•™ê°’ìœ¼ë¡œ ëŒ€ì²´
        if len(outlier_indices) > 0:
            median_power = self.df['power_consumption'].median()
            self.df.loc[outlier_indices, 'power_consumption'] = median_power
            print(f"âœ… ì´ìƒì¹˜ ì²˜ë¦¬ ì™„ë£Œ: {len(outlier_indices)}ê°œ ì´ìƒì¹˜ë¥¼ ì¤‘ì•™ê°’ìœ¼ë¡œ ëŒ€ì²´")
        else:
            print("âœ… ì´ìƒì¹˜ê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        return self.df
    
    def encode_categorical_features(self):
        """ë²”ì£¼í˜• íŠ¹ì„± ì¸ì½”ë”©"""
        print("ğŸ·ï¸ ë²”ì£¼í˜• íŠ¹ì„± ì¸ì½”ë”© ì¤‘...")
        
        categorical_columns = ['building_id', 'room_type', 'season', 'time_period', 
                              'temp_category', 'occupancy_level', 'power_quantile', 'power_category']
        
        for col in categorical_columns:
            if col in self.df.columns:
                # Label Encoding
                le = LabelEncoder()
                self.df[f'{col}_encoded'] = le.fit_transform(self.df[col].astype(str))
                self.label_encoders[col] = le
                
                # One-Hot Encoding (ì„ íƒì )
                if col in ['building_id', 'season', 'time_period']:
                    dummies = pd.get_dummies(self.df[col], prefix=col)
                    self.df = pd.concat([self.df, dummies], axis=1)
        
        print("âœ… ë²”ì£¼í˜• íŠ¹ì„± ì¸ì½”ë”© ì™„ë£Œ")
        return self.df
    
    def scale_numerical_features(self, method='standard'):
        """ìˆ˜ì¹˜í˜• íŠ¹ì„± ìŠ¤ì¼€ì¼ë§"""
        print("ğŸ“ ìˆ˜ì¹˜í˜• íŠ¹ì„± ìŠ¤ì¼€ì¼ë§ ì¤‘...")
        
        # ìŠ¤ì¼€ì¼ë§í•  ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ ì„ íƒ
        numerical_columns = [
            'temperature', 'humidity', 'occupancy', 'floor',
            'temperature_squared', 'temperature_cubed', 'temp_humidity_interaction',
            'feels_like_temp', 'heating_degree_days', 'cooling_degree_days',
            'building_floor_area', 'building_efficiency_score', 'floor_height_factor',
            'building_avg_power', 'building_power_std'
        ]
        
        # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì„ íƒ
        existing_columns = [col for col in numerical_columns if col in self.df.columns]
        
        if method == 'standard':
            scaler = StandardScaler()
        elif method == 'minmax':
            scaler = MinMaxScaler()
        
        # ìŠ¤ì¼€ì¼ë§ ì ìš©
        self.df[existing_columns] = scaler.fit_transform(self.df[existing_columns])
        self.scalers['numerical'] = scaler
        
        print(f"âœ… ìˆ˜ì¹˜í˜• íŠ¹ì„± ìŠ¤ì¼€ì¼ë§ ì™„ë£Œ: {len(existing_columns)}ê°œ ì»¬ëŸ¼")
        return self.df
    
    def select_features(self):
        """ìµœì¢… íŠ¹ì„± ì„ íƒ"""
        print("ğŸ¯ ìµœì¢… íŠ¹ì„± ì„ íƒ ì¤‘...")
        
        # ì œê±°í•  ì»¬ëŸ¼ë“¤
        columns_to_drop = [
            'timestamp', 'season', 'time_period', 'temp_category', 
            'occupancy_level', 'power_quantile', 'power_category'
        ]
        
        # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì œê±°
        existing_drop_columns = [col for col in columns_to_drop if col in self.df.columns]
        self.df = self.df.drop(columns=existing_drop_columns)
        
        # íŠ¹ì„± ì»¬ëŸ¼ ëª©ë¡ ì €ì¥
        self.feature_columns = [col for col in self.df.columns 
                               if col not in [self.target_column, 'index']]
        
        print(f"âœ… ìµœì¢… íŠ¹ì„± ì„ íƒ ì™„ë£Œ: {len(self.feature_columns)}ê°œ íŠ¹ì„±")
        return self.df
    
    def save_processed_data(self, output_path='data/processed/preprocessed_building_data.csv'):
        """ì „ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥"""
        print("ğŸ’¾ ì „ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥ ì¤‘...")
        
        # ì „ì²˜ë¦¬ ì •ë³´ ì €ì¥
        preprocessing_info = {
            'timestamp': datetime.now().isoformat(),
            'original_shape': (43800, 8),
            'processed_shape': self.df.shape,
            'feature_count': len(self.feature_columns),
            'target_column': self.target_column,
            'scalers_used': list(self.scalers.keys()),
            'encoders_used': list(self.label_encoders.keys())
        }
        
        # ë°ì´í„° ì €ì¥
        self.df.to_csv(output_path, index=False)
        
        # ì „ì²˜ë¦¬ ì •ë³´ë¥¼ JSONìœ¼ë¡œ ì €ì¥
        with open('data/processed/preprocessing_info.json', 'w', encoding='utf-8') as f:
            json.dump(preprocessing_info, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… ì „ì²˜ë¦¬ ì™„ë£Œ! ì €ì¥ ìœ„ì¹˜: {output_path}")
        print(f"ğŸ“Š ìµœì¢… ë°ì´í„° í¬ê¸°: {self.df.shape}")
        
        return output_path
    
    def run_full_pipeline(self):
        """ì „ì²´ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        print("ğŸš€ === ìŠ¤ë§ˆíŠ¸ ë¹Œë”© ì—ë„ˆì§€ ë°ì´í„° ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹œì‘ ===")
        
        # 1. ë°ì´í„° ë¡œë“œ
        self.load_data()
        
        # 2. ì‹œê³„ì—´ íŠ¹ì„± ìƒì„±
        self.create_time_features()
        
        # 3. ì˜¨ë„ ê´€ë ¨ íŠ¹ì„± ìƒì„±
        self.create_temperature_features()
        
        # 4. ê³µì‹¤ë¥  ê´€ë ¨ íŠ¹ì„± ìƒì„±
        self.create_occupancy_features()
        
        # 5. ê±´ë¬¼ ê´€ë ¨ íŠ¹ì„± ìƒì„±
        self.create_building_features()
        
        # 6. ì „ë ¥ ì‚¬ìš©ëŸ‰ ê´€ë ¨ íŠ¹ì„± ìƒì„±
        self.create_power_features()
        
        # 7. ìƒí˜¸ì‘ìš© íŠ¹ì„± ìƒì„±
        self.create_interaction_features()
        
        # 8. ê²°ì¸¡ê°’ ì²˜ë¦¬
        self.handle_missing_values()
        
        # 9. ì´ìƒì¹˜ ì²˜ë¦¬
        self.detect_and_handle_outliers()
        
        # 10. ë²”ì£¼í˜• íŠ¹ì„± ì¸ì½”ë”©
        self.encode_categorical_features()
        
        # 11. ìˆ˜ì¹˜í˜• íŠ¹ì„± ìŠ¤ì¼€ì¼ë§
        self.scale_numerical_features()
        
        # 12. ìµœì¢… íŠ¹ì„± ì„ íƒ
        self.select_features()
        
        # 13. ë°ì´í„° ì €ì¥
        output_path = self.save_processed_data()
        
        print("ğŸ‰ === ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ ===")
        
        return self.df, output_path

print("âœ… ì „ì²˜ë¦¬ í´ë˜ìŠ¤ ì •ì˜ ì™„ë£Œ!")
```

---

## 4ë‹¨ê³„: ì „ì²˜ë¦¬ ì‹¤í–‰

```python
# ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
preprocessor = SmartBuildingPreprocessor()
processed_df, output_path = preprocessor.run_full_pipeline()

print(f"\nğŸ‰ ì „ì²˜ë¦¬ ì™„ë£Œ!")
print(f"ğŸ“Š ìµœì¢… ë°ì´í„° í¬ê¸°: {processed_df.shape}")
print(f"ğŸ’¾ ì €ì¥ ìœ„ì¹˜: {output_path}")
print(f"ğŸ¯ íƒ€ê²Ÿ ë³€ìˆ˜: {preprocessor.target_column}")
print(f"ğŸ”§ íŠ¹ì„± ê°œìˆ˜: {len(preprocessor.feature_columns)}")
```

---

## 5ë‹¨ê³„: ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ ê°œë°œ

```python
class SmartBuildingMLModels:
    """ìŠ¤ë§ˆíŠ¸ ë¹Œë”© ì—ë„ˆì§€ ì˜ˆì¸¡ ëª¨ë¸ í´ë˜ìŠ¤"""
    
    def __init__(self, data_path='data/processed/preprocessed_building_data.csv'):
        self.data_path = data_path
        self.models = {}
        self.model_scores = {}
        self.feature_importance = {}
        self.best_model = None
        self.scaler = StandardScaler()
        
    def load_and_prepare_data(self):
        """ë°ì´í„° ë¡œë“œ ë° ëª¨ë¸ í•™ìŠµ ì¤€ë¹„"""
        print("ğŸ“Š ë°ì´í„° ë¡œë“œ ë° ëª¨ë¸ í•™ìŠµ ì¤€ë¹„ ì¤‘...")
        
        # ì „ì²˜ë¦¬ëœ ë°ì´í„° ë¡œë“œ
        self.df = pd.read_csv(self.data_path)
        
        # ìˆ˜ì¹˜í˜• íŠ¹ì„±ë§Œ ì„ íƒ
        numeric_features = self.df.select_dtypes(include=[np.number]).columns.tolist()
        
        # íƒ€ê²Ÿ ë³€ìˆ˜ ë¶„ë¦¬
        self.target = 'power_consumption'
        if self.target in numeric_features:
            numeric_features.remove(self.target)
        
        # íŠ¹ì„±ê³¼ íƒ€ê²Ÿ ë¶„ë¦¬
        self.X = self.df[numeric_features]
        self.y = self.df[self.target]
        
        # ë¬´í•œê°’ ì²˜ë¦¬
        self.X = self.X.replace([np.inf, -np.inf], np.nan)
        self.X = self.X.fillna(self.X.median())
        
        # í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë¶„í•  (ì‹œê³„ì—´ ê³ ë ¤)
        train_size = int(len(self.X) * 0.8)
        self.X_train = self.X[:train_size]
        self.X_test = self.X[train_size:]
        self.y_train = self.y[:train_size]
        self.y_test = self.y[train_size:]
        
        # íŠ¹ì„± ìŠ¤ì¼€ì¼ë§
        self.X_train_scaled = self.scaler.fit_transform(self.X_train)
        self.X_test_scaled = self.scaler.transform(self.X_test)
        
        print(f"âœ… ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ: {self.X_train.shape[0]} í›ˆë ¨, {self.X_test.shape[0]} í…ŒìŠ¤íŠ¸")
        print(f"ğŸ”§ íŠ¹ì„± ê°œìˆ˜: {self.X_train.shape[1]}")
        
        return self.X_train, self.X_test, self.y_train, self.y_test
    
    def evaluate_model(self, model, X_train, X_test, y_train, y_test, model_name):
        """ëª¨ë¸ í‰ê°€"""
        # í›ˆë ¨ ë° ì˜ˆì¸¡
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        
        # í‰ê°€ ì§€í‘œ ê³„ì‚°
        mse = mean_squared_error(y_test, y_pred)
        rmse = np.sqrt(mse)
        mae = mean_absolute_error(y_test, y_pred)
        r2 = r2_score(y_test, y_pred)
        
        # ìƒëŒ€ ì˜¤ì°¨ ê³„ì‚°
        mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100
        
        # êµì°¨ ê²€ì¦
        cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='r2')
        
        results = {
            'RMSE': rmse,
            'MAE': mae,
            'R2': r2,
            'MAPE': mape,
            'CV_R2_mean': cv_scores.mean(),
            'CV_R2_std': cv_scores.std()
        }
        
        print(f"{model_name} ì„±ëŠ¥:")
        print(f"  RMSE: {rmse:.4f}")
        print(f"  MAE: {mae:.4f}")
        print(f"  RÂ²: {r2:.4f}")
        print(f"  MAPE: {mape:.2f}%")
        print(f"  CV RÂ²: {cv_scores.mean():.4f} (Â±{cv_scores.std():.4f})")
        
        return model, results, y_pred
    
    def train_ensemble_models(self):
        """ì•™ìƒë¸” ëª¨ë¸ í›ˆë ¨"""
        print("=== ì•™ìƒë¸” ëª¨ë¸ í›ˆë ¨ ì‹œì‘ ===")
        
        # 1. Random Forest
        print("Random Forest í›ˆë ¨ ì¤‘...")
        rf_model, rf_results, rf_pred = self.evaluate_model(
            RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1),
            self.X_train, self.X_test, self.y_train, self.y_test, "Random Forest"
        )
        self.models['Random_Forest'] = rf_model
        self.model_scores['Random_Forest'] = rf_results
        self.feature_importance['Random_Forest'] = rf_model.feature_importances_
        
        # 2. XGBoost
        print("XGBoost í›ˆë ¨ ì¤‘...")
        xgb_model, xgb_results, xgb_pred = self.evaluate_model(
            xgb.XGBRegressor(n_estimators=100, random_state=42, n_jobs=-1),
            self.X_train, self.X_test, self.y_train, self.y_test, "XGBoost"
        )
        self.models['XGBoost'] = xgb_model
        self.model_scores['XGBoost'] = xgb_results
        self.feature_importance['XGBoost'] = xgb_model.feature_importances_
        
        # 3. LightGBM
        print("LightGBM í›ˆë ¨ ì¤‘...")
        lgb_model, lgb_results, lgb_pred = self.evaluate_model(
            lgb.LGBMRegressor(n_estimators=100, random_state=42, n_jobs=-1),
            self.X_train, self.X_test, self.y_train, self.y_test, "LightGBM"
        )
        self.models['LightGBM'] = lgb_model
        self.model_scores['LightGBM'] = lgb_results
        self.feature_importance['LightGBM'] = lgb_model.feature_importances_
        
        return rf_pred, xgb_pred, lgb_pred
    
    def compare_models(self):
        """ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ"""
        print("=== ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ===")
        
        # ê²°ê³¼ í…Œì´ë¸” ìƒì„±
        results_df = pd.DataFrame(self.model_scores).T
        
        # ì„±ëŠ¥ ìˆœìœ„
        results_df['Rank'] = results_df['R2'].rank(ascending=False)
        results_df = results_df.sort_values('Rank')
        
        print("\nëª¨ë¸ ì„±ëŠ¥ ìˆœìœ„:")
        for idx, (model_name, row) in enumerate(results_df.iterrows(), 1):
            print(f"{idx:2d}. {model_name:<20} | RÂ²: {row['R2']:.4f} | RMSE: {row['RMSE']:.4f} | MAPE: {row['MAPE']:.2f}%")
        
        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì„ íƒ
        best_model_name = results_df.index[0]
        self.best_model = self.models[best_model_name]
        
        print(f"\nğŸ† ìµœê³  ì„±ëŠ¥ ëª¨ë¸: {best_model_name}")
        print(f"   RÂ² Score: {results_df.loc[best_model_name, 'R2']:.4f}")
        print(f"   RMSE: {results_df.loc[best_model_name, 'RMSE']:.4f}")
        print(f"   MAPE: {results_df.loc[best_model_name, 'MAPE']:.2f}%")
        
        return results_df
    
    def save_models(self, output_dir='models/'):
        """ëª¨ë¸ ì €ì¥"""
        os.makedirs(output_dir, exist_ok=True)
        
        print("ëª¨ë¸ ì €ì¥ ì¤‘...")
        
        # ê° ëª¨ë¸ ì €ì¥
        for model_name, model in self.models.items():
            model_path = os.path.join(output_dir, f'{model_name}.pkl')
            joblib.dump(model, model_path)
            print(f"  {model_name} ì €ì¥: {model_path}")
        
        # ìŠ¤ì¼€ì¼ëŸ¬ ì €ì¥
        scaler_path = os.path.join(output_dir, 'scaler.pkl')
        joblib.dump(self.scaler, scaler_path)
        print(f"  Scaler ì €ì¥: {scaler_path}")
        
        # ëª¨ë¸ ì„±ëŠ¥ ê²°ê³¼ ì €ì¥
        results_df = pd.DataFrame(self.model_scores).T
        results_path = os.path.join(output_dir, 'model_performance.csv')
        results_df.to_csv(results_path)
        print(f"  ì„±ëŠ¥ ê²°ê³¼ ì €ì¥: {results_path}")
        
        # íŠ¹ì„± ì¤‘ìš”ë„ ì €ì¥
        if self.feature_importance:
            importance_df = pd.DataFrame({
                'feature': self.X_train.columns,
                'importance': self.feature_importance['XGBoost']
            }).sort_values('importance', ascending=False)
            
            importance_path = os.path.join(output_dir, 'feature_importance.csv')
            importance_df.to_csv(importance_path, index=False)
            print(f"  íŠ¹ì„± ì¤‘ìš”ë„ ì €ì¥: {importance_path}")
    
    def run_full_pipeline(self):
        """ì „ì²´ ë¨¸ì‹ ëŸ¬ë‹ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        print("=== ìŠ¤ë§ˆíŠ¸ ë¹Œë”© ì—ë„ˆì§€ ë¨¸ì‹ ëŸ¬ë‹ íŒŒì´í”„ë¼ì¸ ì‹œì‘ ===")
        
        # 1. ë°ì´í„° ì¤€ë¹„
        self.load_and_prepare_data()
        
        # 2. ì•™ìƒë¸” ëª¨ë¸ í›ˆë ¨
        self.train_ensemble_models()
        
        # 3. ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ
        results_df = self.compare_models()
        
        # 4. ëª¨ë¸ ì €ì¥
        self.save_models()
        
        print("=== ë¨¸ì‹ ëŸ¬ë‹ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ ===")
        
        return results_df

print("âœ… ë¨¸ì‹ ëŸ¬ë‹ í´ë˜ìŠ¤ ì •ì˜ ì™„ë£Œ!")
```

---

## 6ë‹¨ê³„: ë¨¸ì‹ ëŸ¬ë‹ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰

```python
# ë¨¸ì‹ ëŸ¬ë‹ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
ml_pipeline = SmartBuildingMLModels()
results = ml_pipeline.run_full_pipeline()

print(f"\nğŸ‰ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ ê°œë°œ ì™„ë£Œ!")
print(f"ğŸ† ìµœê³  ì„±ëŠ¥ ëª¨ë¸: {results.index[0]}")
print(f"ğŸ“Š RÂ² Score: {results.iloc[0]['R2']:.4f}")
print(f"ğŸ“ˆ RMSE: {results.iloc[0]['RMSE']:.4f}")
print(f"ğŸ“‰ MAPE: {results.iloc[0]['MAPE']:.2f}%")
print(f"ğŸ’¾ ëª¨ë¸ ì €ì¥ ìœ„ì¹˜: models/")
```

---

## 7ë‹¨ê³„: ê²°ê³¼ ë¶„ì„ ë° ì‹œê°í™”

```python
# ëª¨ë¸ ì„±ëŠ¥ ì‹œê°í™”
fig, axes = plt.subplots(1, 3, figsize=(15, 5))

# RÂ² Score ë¹„êµ
axes[0].bar(results.index, results['R2'])
axes[0].set_title('RÂ² Score ë¹„êµ')
axes[0].set_ylabel('RÂ² Score')
axes[0].tick_params(axis='x', rotation=45)

# RMSE ë¹„êµ
axes[1].bar(results.index, results['RMSE'])
axes[1].set_title('RMSE ë¹„êµ')
axes[1].set_ylabel('RMSE')
axes[1].tick_params(axis='x', rotation=45)

# MAPE ë¹„êµ
axes[2].bar(results.index, results['MAPE'])
axes[2].set_title('MAPE ë¹„êµ')
axes[2].set_ylabel('MAPE (%)')
axes[2].tick_params(axis='x', rotation=45)

plt.tight_layout()
plt.show()

# íŠ¹ì„± ì¤‘ìš”ë„ ì‹œê°í™”
importance_df = pd.read_csv('models/feature_importance.csv')
top_20 = importance_df.head(20)

fig, ax = plt.subplots(figsize=(12, 10))
bars = ax.barh(range(len(top_20)), top_20['importance'])
ax.set_yticks(range(len(top_20)))
ax.set_yticklabels(top_20['feature'], fontsize=10)
ax.set_xlabel('íŠ¹ì„± ì¤‘ìš”ë„', fontsize=12)
ax.set_title('ìƒìœ„ 20ê°œ ì¤‘ìš” íŠ¹ì„±', fontsize=14, fontweight='bold')

plt.tight_layout()
plt.show()

print("ğŸ” ìƒìœ„ 20ê°œ ì¤‘ìš” íŠ¹ì„±:")
for i, (_, row) in enumerate(importance_df.head(20).iterrows(), 1):
    print(f"{i:2d}. {row['feature']:<35} | {row['importance']:.4f}")
```

---

## ğŸ‰ ì™„ë£Œ!

ì´ì œ êµ¬ê¸€ ì½”ë©ì—ì„œ ìŠ¤ë§ˆíŠ¸ ë¹Œë”© ì—ë„ˆì§€ ê´€ë¦¬ ì‹œìŠ¤í…œì˜ ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!

### ì£¼ìš” ê¸°ëŠ¥:
- âœ… **ì „ì²´ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸** (82ê°œ íŠ¹ì„± ìƒì„±)
- âœ… **ë‹¤ì¤‘ ëª¨ë¸ í›ˆë ¨** (Random Forest, XGBoost, LightGBM)
- âœ… **ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ** (RÂ², RMSE, MAPE)
- âœ… **íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„** (ìƒìœ„ 20ê°œ íŠ¹ì„±)
- âœ… **ê²°ê³¼ ì‹œê°í™”** (ì„±ëŠ¥ ë¹„êµ, íŠ¹ì„± ì¤‘ìš”ë„)

### ì˜ˆìƒ ê²°ê³¼:
- **96% ì´ìƒì˜ ì •í™•ë„**ë¡œ ì „ë ¥ ì‚¬ìš©ëŸ‰ ì˜ˆì¸¡
- **3-5%ì˜ í‰ê·  ì ˆëŒ€ ì˜¤ì°¨**
- **ì•ˆì •ì ì¸ êµì°¨ ê²€ì¦ ì„±ëŠ¥**

### ë‹¤ìŒ ë‹¨ê³„:
- ì›¹ ëŒ€ì‹œë³´ë“œ ê°œë°œ
- ì‹¤ì‹œê°„ API êµ¬ì¶•
- IoT ì„¼ì„œ ì—°ë™
- ìë™ ì œì–´ ì‹œìŠ¤í…œ êµ¬í˜„

---

## ğŸ“ ë¬¸ì œ í•´ê²°

### ìì£¼ ë°œìƒí•˜ëŠ” ì˜¤ë¥˜:

1. **ë©”ëª¨ë¦¬ ë¶€ì¡±**
   - ëŸ°íƒ€ì„ ìœ í˜•ì„ GPUë¡œ ë³€ê²½
   - ë¶ˆí•„ìš”í•œ ë³€ìˆ˜ ì‚­ì œ

2. **ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ì˜¤ë¥˜**
   - ëŸ°íƒ€ì„ ì¬ì‹œì‘ í›„ ë‹¤ì‹œ ì„¤ì¹˜
   - GPU ëŸ°íƒ€ì„ ì‚¬ìš© ì‹œ CUDA ë²„ì „ í™•ì¸

3. **íŒŒì¼ ì—…ë¡œë“œ ì˜¤ë¥˜**
   - íŒŒì¼ëª…ì´ ì •í™•í•œì§€ í™•ì¸
   - íŒŒì¼ í¬ê¸°ê°€ ì ì ˆí•œì§€ í™•ì¸

## ğŸ”— ì¶”ê°€ ë¦¬ì†ŒìŠ¤

- [Google Colab ê³µì‹ ë¬¸ì„œ](https://colab.research.google.com/)
- [XGBoost ê³µì‹ ë¬¸ì„œ](https://xgboost.readthedocs.io/)
- [LightGBM ê³µì‹ ë¬¸ì„œ](https://lightgbm.readthedocs.io/)
- [Scikit-learn ê³µì‹ ë¬¸ì„œ](https://scikit-learn.org/)
