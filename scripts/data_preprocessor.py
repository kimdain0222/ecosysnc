#!/usr/bin/env python3
"""
ìŠ¤ë§ˆíŠ¸ ë¹Œë”© ì—ë„ˆì§€ ê´€ë¦¬ ì‹œìŠ¤í…œ (SBEMS) - ë°ì´í„° ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
ìµœì í™”ëœ íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ ë° ë°ì´í„° ì •ì œë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder
from sklearn.ensemble import IsolationForest
from scipy import stats
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class SmartBuildingPreprocessor:
    """ìŠ¤ë§ˆíŠ¸ ë¹Œë”© ì—ë„ˆì§€ ë°ì´í„° ì „ì²˜ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, data_path='data/processed/synthetic_building_data.csv'):
        self.data_path = data_path
        self.scalers = {}
        self.label_encoders = {}
        self.feature_columns = []
        self.target_column = 'power_consumption'
        
    def load_data(self):
        """ë°ì´í„° ë¡œë“œ ë° ê¸°ë³¸ ì •ë³´ í™•ì¸"""
        logger.info("ë°ì´í„° ë¡œë“œ ì¤‘...")
        self.df = pd.read_csv(self.data_path)
        logger.info(f"ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {self.df.shape}")
        
        # íƒ€ì„ìŠ¤íƒ¬í”„ ë³€í™˜
        self.df['timestamp'] = pd.to_datetime(self.df['timestamp'])
        self.df = self.df.sort_values('timestamp').reset_index(drop=True)
        
        return self.df
    
    def create_time_features(self):
        """ì‹œê³„ì—´ íŠ¹ì„± ìƒì„±"""
        logger.info("ì‹œê³„ì—´ íŠ¹ì„± ìƒì„± ì¤‘...")
        
        # ê¸°ë³¸ ì‹œê°„ íŠ¹ì„±
        self.df['hour'] = self.df['timestamp'].dt.hour
        self.df['day_of_week'] = self.df['timestamp'].dt.dayofweek
        self.df['month'] = self.df['timestamp'].dt.month
        self.df['day_of_year'] = self.df['timestamp'].dt.dayofyear
        self.df['week_of_year'] = self.df['timestamp'].dt.isocalendar().week
        
        # ê³„ì ˆ íŠ¹ì„±
        self.df['season'] = pd.cut(self.df['month'], 
                                  bins=[0, 3, 6, 9, 12], 
                                  labels=['ê²¨ìš¸', 'ë´„', 'ì—¬ë¦„', 'ê°€ì„'])
        
        # ì—…ë¬´ ê´€ë ¨ íŠ¹ì„±
        self.df['is_weekend'] = (self.df['day_of_week'] >= 5).astype(int)
        self.df['is_business_hour'] = ((self.df['hour'] >= 8) & (self.df['hour'] <= 18)).astype(int)
        self.df['is_peak_hour'] = ((self.df['hour'] >= 9) & (self.df['hour'] <= 17)).astype(int)
        self.df['is_night'] = ((self.df['hour'] >= 22) | (self.df['hour'] <= 6)).astype(int)
        
        # ì‹œê°„ëŒ€ë³„ ì¹´í…Œê³ ë¦¬
        self.df['time_period'] = pd.cut(self.df['hour'], 
                                       bins=[0, 6, 12, 18, 24], 
                                       labels=['ìƒˆë²½', 'ì˜¤ì „', 'ì˜¤í›„', 'ì €ë…'])
        
        logger.info("ì‹œê³„ì—´ íŠ¹ì„± ìƒì„± ì™„ë£Œ")
        return self.df
    
    def create_temperature_features(self):
        """ì˜¨ë„ ê´€ë ¨ íŠ¹ì„± ìƒì„±"""
        logger.info("ì˜¨ë„ ê´€ë ¨ íŠ¹ì„± ìƒì„± ì¤‘...")
        
        # ì˜¨ë„ ë¹„ì„ í˜• íŠ¹ì„±
        self.df['temperature_squared'] = self.df['temperature'] ** 2
        self.df['temperature_cubed'] = self.df['temperature'] ** 3
        
        # ì˜¨ìŠµë„ ìƒí˜¸ì‘ìš©
        self.df['temp_humidity_interaction'] = self.df['temperature'] * self.df['humidity']
        
        # ì²´ê°ì˜¨ë„ (ê°„ë‹¨í•œ ê³µì‹)
        self.df['feels_like_temp'] = (0.5 * self.df['temperature'] + 
                                     0.3 * self.df['humidity'] + 
                                     0.2 * (self.df['temperature'] * self.df['humidity'] / 100))
        
        # ë‚œë°©/ëƒ‰ë°©ë„ì¼
        base_temp = 18  # ê¸°ì¤€ì˜¨ë„
        self.df['heating_degree_days'] = np.maximum(base_temp - self.df['temperature'], 0)
        self.df['cooling_degree_days'] = np.maximum(self.df['temperature'] - base_temp, 0)
        
        # ì¾Œì êµ¬ê°„
        self.df['comfort_zone'] = ((self.df['temperature'] >= 18) & 
                                  (self.df['temperature'] <= 26)).astype(int)
        
        # ì˜¨ë„ êµ¬ê°„ë³„ ì¹´í…Œê³ ë¦¬
        self.df['temp_category'] = pd.cut(self.df['temperature'], 
                                         bins=[-10, 0, 10, 20, 30, 50], 
                                         labels=['ë§¤ìš°ì¶”ì›€', 'ì¶”ì›€', 'ì‹œì›í•¨', 'ë”°ëœ»í•¨', 'ë”ì›€'])
        
        logger.info("ì˜¨ë„ ê´€ë ¨ íŠ¹ì„± ìƒì„± ì™„ë£Œ")
        return self.df
    
    def create_occupancy_features(self):
        """ê³µì‹¤ë¥  ê´€ë ¨ íŠ¹ì„± ìƒì„±"""
        logger.info("ê³µì‹¤ë¥  ê´€ë ¨ íŠ¹ì„± ìƒì„± ì¤‘...")
        
        # ê³µì‹¤ ì´ì§„ ë¶„ë¥˜
        self.df['occupancy_binary'] = (self.df['occupancy'] > 0).astype(int)
        
        # ê³µì‹¤ ìˆ˜ì¤€ ë¶„ë¥˜
        self.df['occupancy_level'] = pd.cut(self.df['occupancy'], 
                                           bins=[0, 20, 60, 100], 
                                           labels=['ë‚®ìŒ', 'ë³´í†µ', 'ë†’ìŒ'])
        
        # ì‹œì°¨ íŠ¹ì„± (lag features)
        for lag in [1, 2, 3, 6, 12, 24]:
            self.df[f'occupancy_lag_{lag}h'] = self.df['occupancy'].shift(lag)
        
        # ì´ë™í‰ê· 
        for window in [3, 6, 12, 24]:
            self.df[f'occupancy_rolling_mean_{window}h'] = self.df['occupancy'].rolling(window=window).mean()
            self.df[f'occupancy_rolling_std_{window}h'] = self.df['occupancy'].rolling(window=window).std()
        
        # ê³µì‹¤ ë³€í™”ìœ¨
        self.df['occupancy_change_rate'] = self.df['occupancy'].pct_change()
        
        # ê³µì‹¤ íŒ¨í„´ íŠ¹ì„±
        self.df['occupancy_trend'] = self.df['occupancy'].rolling(window=6).apply(
            lambda x: np.polyfit(range(len(x)), x, 1)[0] if len(x) > 1 else 0
        )
        
        logger.info("ê³µì‹¤ë¥  ê´€ë ¨ íŠ¹ì„± ìƒì„± ì™„ë£Œ")
        return self.df
    
    def create_building_features(self):
        """ê±´ë¬¼ ê´€ë ¨ íŠ¹ì„± ìƒì„±"""
        logger.info("ê±´ë¬¼ ê´€ë ¨ íŠ¹ì„± ìƒì„± ì¤‘...")
        
        # ê±´ë¬¼ë³„ ê°€ìƒ ë©´ì  (ì¸µìˆ˜ ê¸°ë°˜)
        self.df['building_floor_area'] = self.df['floor'] * 500  # ì¸µë‹¹ 500mÂ² ê°€ì •
        
        # ê±´ë¬¼ë³„ ì—ë„ˆì§€ íš¨ìœ¨ì„± ì ìˆ˜ (ê°€ìƒ)
        building_efficiency = {
            'B001': 0.8, 'B002': 0.9, 'B003': 0.7, 'B004': 0.85, 'B005': 0.75
        }
        self.df['building_efficiency_score'] = self.df['building_id'].map(building_efficiency)
        
        # ì¸µìˆ˜ë³„ íŠ¹ì„±
        self.df['floor_height_factor'] = self.df['floor'] * 3  # ì¸µë‹¹ 3m ë†’ì´
        self.df['is_ground_floor'] = (self.df['floor'] == 1).astype(int)
        self.df['is_top_floor'] = (self.df['floor'] == 5).astype(int)
        
        # ê±´ë¬¼ë³„ í‰ê·  ì „ë ¥ ì‚¬ìš©ëŸ‰
        building_avg_power = self.df.groupby('building_id')['power_consumption'].mean()
        self.df['building_avg_power'] = self.df['building_id'].map(building_avg_power)
        
        # ê±´ë¬¼ë³„ ì „ë ¥ ì‚¬ìš© íŒ¨í„´ (í‘œì¤€í¸ì°¨)
        building_power_std = self.df.groupby('building_id')['power_consumption'].std()
        self.df['building_power_std'] = self.df['building_id'].map(building_power_std)
        
        logger.info("ê±´ë¬¼ ê´€ë ¨ íŠ¹ì„± ìƒì„± ì™„ë£Œ")
        return self.df
    
    def create_power_features(self):
        """ì „ë ¥ ì‚¬ìš©ëŸ‰ ê´€ë ¨ íŠ¹ì„± ìƒì„±"""
        logger.info("ì „ë ¥ ì‚¬ìš©ëŸ‰ ê´€ë ¨ íŠ¹ì„± ìƒì„± ì¤‘...")
        
        # ì „ë ¥ ì‚¬ìš©ëŸ‰ ë³€í™”ìœ¨
        self.df['power_change_rate'] = self.df['power_consumption'].pct_change()
        
        # ì „ë ¥ ì‚¬ìš©ëŸ‰ ì´ë™í‰ê· 
        for window in [3, 6, 12, 24]:
            self.df[f'power_rolling_mean_{window}h'] = self.df['power_consumption'].rolling(window=window).mean()
            self.df[f'power_rolling_std_{window}h'] = self.df['power_consumption'].rolling(window=window).std()
        
        # ì „ë ¥ ì‚¬ìš©ëŸ‰ íŠ¸ë Œë“œ
        self.df['power_trend'] = self.df['power_consumption'].rolling(window=6).apply(
            lambda x: np.polyfit(range(len(x)), x, 1)[0] if len(x) > 1 else 0
        )
        
        # ì „ë ¥ ì‚¬ìš©ëŸ‰ ë¶„ìœ„ìˆ˜
        self.df['power_quantile'] = pd.qcut(self.df['power_consumption'], 
                                           q=5, labels=['ë§¤ìš°ë‚®ìŒ', 'ë‚®ìŒ', 'ë³´í†µ', 'ë†’ìŒ', 'ë§¤ìš°ë†’ìŒ'])
        
        # ì „ë ¥ ì‚¬ìš©ëŸ‰ êµ¬ê°„
        self.df['power_category'] = pd.cut(self.df['power_consumption'], 
                                          bins=[0, 10, 30, 60, 100, 200], 
                                          labels=['ë¯¸ì‚¬ìš©', 'ì €ì „ë ¥', 'ë³´í†µ', 'ê³ ì „ë ¥', 'ìµœê³ ì „ë ¥'])
        
        logger.info("ì „ë ¥ ì‚¬ìš©ëŸ‰ ê´€ë ¨ íŠ¹ì„± ìƒì„± ì™„ë£Œ")
        return self.df
    
    def handle_missing_values(self):
        """ê²°ì¸¡ê°’ ì²˜ë¦¬"""
        logger.info("ê²°ì¸¡ê°’ ì²˜ë¦¬ ì¤‘...")
        
        initial_missing = self.df.isnull().sum().sum()
        if initial_missing == 0:
            logger.info("ê²°ì¸¡ê°’ì´ ì—†ìŠµë‹ˆë‹¤.")
            return self.df
        
        # ì‹œê³„ì—´ ë°ì´í„°ì˜ ê²½ìš° ì „ì§„ ì±„ìš°ê¸°(forward fill) ì‚¬ìš©
        self.df = self.df.fillna(method='ffill')
        
        # ì—¬ì „íˆ ë‚¨ì€ ê²°ì¸¡ê°’ì€ í›„ì§„ ì±„ìš°ê¸°(backward fill) ì‚¬ìš©
        self.df = self.df.fillna(method='bfill')
        
        # ìˆ«ìí˜• ì»¬ëŸ¼ì˜ ê²½ìš° í‰ê· ê°’ìœ¼ë¡œ ì±„ìš°ê¸°
        numeric_columns = self.df.select_dtypes(include=[np.number]).columns
        self.df[numeric_columns] = self.df[numeric_columns].fillna(self.df[numeric_columns].mean())
        
        final_missing = self.df.isnull().sum().sum()
        logger.info(f"ê²°ì¸¡ê°’ ì²˜ë¦¬ ì™„ë£Œ: {initial_missing} -> {final_missing}")
        
        return self.df
    
    def detect_and_handle_outliers(self, method='isolation_forest'):
        """ì´ìƒì¹˜ íƒì§€ ë° ì²˜ë¦¬"""
        logger.info("ì´ìƒì¹˜ íƒì§€ ë° ì²˜ë¦¬ ì¤‘...")
        
        # ì „ë ¥ ì‚¬ìš©ëŸ‰ ì´ìƒì¹˜ íƒì§€
        power_consumption = self.df['power_consumption'].values.reshape(-1, 1)
        
        if method == 'isolation_forest':
            # Isolation Forest ì‚¬ìš©
            iso_forest = IsolationForest(contamination=0.1, random_state=42)
            outliers = iso_forest.fit_predict(power_consumption)
            outlier_indices = np.where(outliers == -1)[0]
        
        elif method == 'iqr':
            # IQR ë°©ë²•
            Q1 = self.df['power_consumption'].quantile(0.25)
            Q3 = self.df['power_consumption'].quantile(0.75)
            IQR = Q3 - Q1
            lower_bound = Q1 - 1.5 * IQR
            upper_bound = Q3 + 1.5 * IQR
            outlier_indices = self.df[
                (self.df['power_consumption'] < lower_bound) | 
                (self.df['power_consumption'] > upper_bound)
            ].index
        
        elif method == 'zscore':
            # Z-score ë°©ë²•
            z_scores = np.abs(stats.zscore(power_consumption))
            outlier_indices = np.where(z_scores > 3)[0]
        
        # ì´ìƒì¹˜ë¥¼ ì¤‘ì•™ê°’ìœ¼ë¡œ ëŒ€ì²´
        if len(outlier_indices) > 0:
            median_power = self.df['power_consumption'].median()
            self.df.loc[outlier_indices, 'power_consumption'] = median_power
            logger.info(f"ì´ìƒì¹˜ ì²˜ë¦¬ ì™„ë£Œ: {len(outlier_indices)}ê°œ ì´ìƒì¹˜ë¥¼ ì¤‘ì•™ê°’ìœ¼ë¡œ ëŒ€ì²´")
        else:
            logger.info("ì´ìƒì¹˜ê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        return self.df
    
    def encode_categorical_features(self):
        """ë²”ì£¼í˜• íŠ¹ì„± ì¸ì½”ë”©"""
        logger.info("ë²”ì£¼í˜• íŠ¹ì„± ì¸ì½”ë”© ì¤‘...")
        
        categorical_columns = ['building_id', 'room_type', 'season', 'time_period', 
                              'temp_category', 'occupancy_level', 'power_quantile', 'power_category']
        
        for col in categorical_columns:
            if col in self.df.columns:
                # Label Encoding
                le = LabelEncoder()
                self.df[f'{col}_encoded'] = le.fit_transform(self.df[col].astype(str))
                self.label_encoders[col] = le
                
                # One-Hot Encoding (ì„ íƒì )
                if col in ['building_id', 'season', 'time_period']:
                    dummies = pd.get_dummies(self.df[col], prefix=col)
                    self.df = pd.concat([self.df, dummies], axis=1)
        
        logger.info("ë²”ì£¼í˜• íŠ¹ì„± ì¸ì½”ë”© ì™„ë£Œ")
        return self.df
    
    def scale_numerical_features(self, method='standard'):
        """ìˆ˜ì¹˜í˜• íŠ¹ì„± ìŠ¤ì¼€ì¼ë§"""
        logger.info("ìˆ˜ì¹˜í˜• íŠ¹ì„± ìŠ¤ì¼€ì¼ë§ ì¤‘...")
        
        # ìŠ¤ì¼€ì¼ë§í•  ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ ì„ íƒ
        numerical_columns = [
            'temperature', 'humidity', 'occupancy', 'floor',
            'temperature_squared', 'temperature_cubed', 'temp_humidity_interaction',
            'feels_like_temp', 'heating_degree_days', 'cooling_degree_days',
            'building_floor_area', 'building_efficiency_score', 'floor_height_factor',
            'building_avg_power', 'building_power_std'
        ]
        
        # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì„ íƒ
        existing_columns = [col for col in numerical_columns if col in self.df.columns]
        
        if method == 'standard':
            scaler = StandardScaler()
        elif method == 'minmax':
            scaler = MinMaxScaler()
        
        # ìŠ¤ì¼€ì¼ë§ ì ìš©
        self.df[existing_columns] = scaler.fit_transform(self.df[existing_columns])
        self.scalers['numerical'] = scaler
        
        logger.info(f"ìˆ˜ì¹˜í˜• íŠ¹ì„± ìŠ¤ì¼€ì¼ë§ ì™„ë£Œ: {len(existing_columns)}ê°œ ì»¬ëŸ¼")
        return self.df
    
    def create_interaction_features(self):
        """ìƒí˜¸ì‘ìš© íŠ¹ì„± ìƒì„±"""
        logger.info("ìƒí˜¸ì‘ìš© íŠ¹ì„± ìƒì„± ì¤‘...")
        
        # ì˜¨ë„ì™€ ê³µì‹¤ë¥  ìƒí˜¸ì‘ìš©
        self.df['temp_occupancy_interaction'] = self.df['temperature'] * self.df['occupancy']
        
        # ì‹œê°„ëŒ€ì™€ ê³µì‹¤ë¥  ìƒí˜¸ì‘ìš©
        self.df['hour_occupancy_interaction'] = self.df['hour'] * self.df['occupancy']
        
        # ê±´ë¬¼ íš¨ìœ¨ì„±ê³¼ ì „ë ¥ ì‚¬ìš©ëŸ‰ ìƒí˜¸ì‘ìš©
        self.df['efficiency_power_interaction'] = self.df['building_efficiency_score'] * self.df['power_consumption']
        
        # ì—…ë¬´ì‹œê°„ê³¼ ê³µì‹¤ë¥  ìƒí˜¸ì‘ìš©
        self.df['business_occupancy_interaction'] = self.df['is_business_hour'] * self.df['occupancy']
        
        # ê³„ì ˆê³¼ ì˜¨ë„ ìƒí˜¸ì‘ìš©
        season_encoded = self.df['season'].astype('category').cat.codes
        self.df['season_temp_interaction'] = season_encoded * self.df['temperature']
        
        logger.info("ìƒí˜¸ì‘ìš© íŠ¹ì„± ìƒì„± ì™„ë£Œ")
        return self.df
    
    def select_features(self):
        """ìµœì¢… íŠ¹ì„± ì„ íƒ"""
        logger.info("ìµœì¢… íŠ¹ì„± ì„ íƒ ì¤‘...")
        
        # ì œê±°í•  ì»¬ëŸ¼ë“¤
        columns_to_drop = [
            'timestamp',  # ì‹œê°„ ì •ë³´ëŠ” ì´ë¯¸ íŠ¹ì„±ìœ¼ë¡œ ì¶”ì¶œë¨
            'season', 'time_period', 'temp_category', 'occupancy_level',  # ì›ë³¸ ë²”ì£¼í˜•
            'power_quantile', 'power_category'  # ì›ë³¸ ë²”ì£¼í˜•
        ]
        
        # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì œê±°
        existing_drop_columns = [col for col in columns_to_drop if col in self.df.columns]
        self.df = self.df.drop(columns=existing_drop_columns)
        
        # íŠ¹ì„± ì»¬ëŸ¼ ëª©ë¡ ì €ì¥
        self.feature_columns = [col for col in self.df.columns 
                               if col not in [self.target_column, 'index']]
        
        logger.info(f"ìµœì¢… íŠ¹ì„± ì„ íƒ ì™„ë£Œ: {len(self.feature_columns)}ê°œ íŠ¹ì„±")
        return self.df
    
    def get_feature_importance_preview(self):
        """íŠ¹ì„± ì¤‘ìš”ë„ ë¯¸ë¦¬ë³´ê¸° (ìƒê´€ê´€ê³„ ê¸°ë°˜)"""
        logger.info("íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„ ì¤‘...")
        
        # ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ë§Œ ì„ íƒí•˜ì—¬ ìƒê´€ê´€ê³„ ê³„ì‚°
        numeric_columns = self.df[self.feature_columns].select_dtypes(include=[np.number]).columns.tolist()
        numeric_columns.append(self.target_column)
        
        # íƒ€ê²Ÿê³¼ì˜ ìƒê´€ê´€ê³„ ê³„ì‚°
        correlations = self.df[numeric_columns].corr()[self.target_column].abs()
        correlations = correlations.sort_values(ascending=False)
        
        # ìƒìœ„ 20ê°œ íŠ¹ì„± ì¶œë ¥
        top_features = correlations.head(20)
        logger.info("ìƒìœ„ 20ê°œ ì¤‘ìš” íŠ¹ì„±:")
        for feature, corr in top_features.items():
            if feature != self.target_column:
                logger.info(f"  {feature}: {corr:.4f}")
        
        return top_features
    
    def save_processed_data(self, output_path='data/processed/preprocessed_building_data.csv'):
        """ì „ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥"""
        logger.info("ì „ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥ ì¤‘...")
        
        # ì „ì²˜ë¦¬ ì •ë³´ ì €ì¥
        preprocessing_info = {
            'timestamp': datetime.now().isoformat(),
            'original_shape': (43800, 8),  # ì›ë³¸ ë°ì´í„° í¬ê¸°
            'processed_shape': self.df.shape,
            'feature_count': len(self.feature_columns),
            'target_column': self.target_column,
            'scalers_used': list(self.scalers.keys()),
            'encoders_used': list(self.label_encoders.keys())
        }
        
        # ë°ì´í„° ì €ì¥
        self.df.to_csv(output_path, index=False)
        
        # ì „ì²˜ë¦¬ ì •ë³´ë¥¼ JSONìœ¼ë¡œ ì €ì¥
        import json
        with open('data/processed/preprocessing_info.json', 'w', encoding='utf-8') as f:
            json.dump(preprocessing_info, f, ensure_ascii=False, indent=2)
        
        logger.info(f"ì „ì²˜ë¦¬ ì™„ë£Œ! ì €ì¥ ìœ„ì¹˜: {output_path}")
        logger.info(f"ìµœì¢… ë°ì´í„° í¬ê¸°: {self.df.shape}")
        
        return output_path
    
    def run_full_pipeline(self):
        """ì „ì²´ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        logger.info("=== ìŠ¤ë§ˆíŠ¸ ë¹Œë”© ì—ë„ˆì§€ ë°ì´í„° ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹œì‘ ===")
        
        # 1. ë°ì´í„° ë¡œë“œ
        self.load_data()
        
        # 2. ì‹œê³„ì—´ íŠ¹ì„± ìƒì„±
        self.create_time_features()
        
        # 3. ì˜¨ë„ ê´€ë ¨ íŠ¹ì„± ìƒì„±
        self.create_temperature_features()
        
        # 4. ê³µì‹¤ë¥  ê´€ë ¨ íŠ¹ì„± ìƒì„±
        self.create_occupancy_features()
        
        # 5. ê±´ë¬¼ ê´€ë ¨ íŠ¹ì„± ìƒì„±
        self.create_building_features()
        
        # 6. ì „ë ¥ ì‚¬ìš©ëŸ‰ ê´€ë ¨ íŠ¹ì„± ìƒì„±
        self.create_power_features()
        
        # 7. ìƒí˜¸ì‘ìš© íŠ¹ì„± ìƒì„±
        self.create_interaction_features()
        
        # 8. ê²°ì¸¡ê°’ ì²˜ë¦¬
        self.handle_missing_values()
        
        # 9. ì´ìƒì¹˜ ì²˜ë¦¬
        self.detect_and_handle_outliers()
        
        # 10. ë²”ì£¼í˜• íŠ¹ì„± ì¸ì½”ë”©
        self.encode_categorical_features()
        
        # 11. ìˆ˜ì¹˜í˜• íŠ¹ì„± ìŠ¤ì¼€ì¼ë§
        self.scale_numerical_features()
        
        # 12. ìµœì¢… íŠ¹ì„± ì„ íƒ
        self.select_features()
        
        # 13. íŠ¹ì„± ì¤‘ìš”ë„ ë¯¸ë¦¬ë³´ê¸°
        self.get_feature_importance_preview()
        
        # 14. ë°ì´í„° ì €ì¥
        output_path = self.save_processed_data()
        
        logger.info("=== ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ ===")
        
        return self.df, output_path

if __name__ == "__main__":
    # ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    preprocessor = SmartBuildingPreprocessor()
    processed_df, output_path = preprocessor.run_full_pipeline()
    
    print(f"\nğŸ‰ ì „ì²˜ë¦¬ ì™„ë£Œ!")
    print(f"ğŸ“Š ìµœì¢… ë°ì´í„° í¬ê¸°: {processed_df.shape}")
    print(f"ğŸ’¾ ì €ì¥ ìœ„ì¹˜: {output_path}")
    print(f"ğŸ¯ íƒ€ê²Ÿ ë³€ìˆ˜: {preprocessor.target_column}")
    print(f"ğŸ”§ íŠ¹ì„± ê°œìˆ˜: {len(preprocessor.feature_columns)}")
